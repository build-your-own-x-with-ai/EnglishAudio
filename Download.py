#!/usr/bin/env python3

import pathlib
import re
import requests
from bs4 import BeautifulSoup

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
    "Referer": "https://mp.weixin.qq.com/",
    "Cookie": ""  # 403æ—¶è¡¥å……å¾®ä¿¡ç™»å½•Cookie
}

def download_audio(audio_url, save_path):
    """ä»…ä¸‹è½½éŸ³é¢‘ï¼Œè·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶"""
    # å…³é”®ï¼šå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡ï¼Œä¸é‡å¤ä¸‹è½½
    if save_path.exists():
        print(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼š{save_path.name}")
        return True
    try:
        response = requests.get(audio_url, headers=HEADERS, stream=True, timeout=15)
        response.raise_for_status()
        with open(save_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)
        print(f"âœ… æˆåŠŸä¸‹è½½ï¼š{save_path.name}")
        return True
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ {save_path.name}ï¼š{str(e)[:50]}")
        return False

def extract_secondary_audio(secondary_url, grade_save_dir):
    try:
        response = requests.get(secondary_url, headers=HEADERS, timeout=10)
        response.raise_for_status()
    except Exception as e:
        print(f"âš ï¸ è®¿é—®äºŒçº§é¡µé¢å¤±è´¥ {secondary_url}ï¼š{str(e)}")
        return

    soup = BeautifulSoup(response.text, "html.parser")
    page_title = soup.find("h1", class_="rich_media_title") or soup.find("h1")
    page_title = page_title.text.strip() if page_title else "æœªå‘½åéŸ³é¢‘"
    safe_title = re.sub(r'[\\/*?:"<>|]', "_", page_title)

    audio_fileid = re.findall(r'voice_encode_fileid="(.*?)"', response.text)
    if audio_fileid:
        audio_url = f"https://res.wx.qq.com/voice/getvoice?mediaid={audio_fileid[0]}"
        audio_save_path = grade_save_dir / f"{safe_title}.mp3"
        download_audio(audio_url, audio_save_path)
    else:
        print(f"âš ï¸ äºŒçº§é¡µé¢ {safe_title} æ— éŸ³é¢‘èµ„æº")

def crawl_grade_audio(main_url, root_save_dir):
    root_path = pathlib.Path(root_save_dir)
    root_path.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“‚ æ ¹ä¿å­˜ç›®å½•å·²åˆ›å»ºï¼š{root_path}")

    try:
        main_response = requests.get(main_url, headers=HEADERS, timeout=10)
        main_response.raise_for_status()
        main_soup = BeautifulSoup(main_response.text, "html.parser")
    except Exception as e:
        print(f"âŒ è®¿é—®ä¸€çº§é¡µé¢å¤±è´¥ï¼š{str(e)}")
        return

    # -------------------------- æ ¸å¿ƒä¿®å¤ï¼šå»é‡å¹´çº§åˆ†åŒº --------------------------
    grade_sections = []
    processed_grades = set()  # ç”¨é›†åˆè®°å½•å·²å¤„ç†çš„å¹´çº§ï¼Œé¿å…é‡å¤
    down_arrow_titles = main_soup.find_all(lambda tag: 
        tag.name in ["p", "div", "h3"] and "â†“â†“" in tag.text
    )

    for title_tag in down_arrow_titles:
        raw_title = title_tag.text.strip()
        grade_match = re.search(r'(ä¸€|äºŒ|ä¸‰|å››|äº”|å…­)å¹´çº§ä¸Šå†Œ\s*(è¯¾æœ¬|å•è¯)', raw_title)
        if not grade_match:
            continue
        
        pure_grade_title = grade_match.group().replace(" ", "")
        # å…³é”®ï¼šå¦‚æœè¯¥å¹´çº§å·²å¤„ç†è¿‡ï¼Œç›´æ¥è·³è¿‡
        if pure_grade_title in processed_grades:
            continue
        processed_grades.add(pure_grade_title)  # æ ‡è®°ä¸ºå·²å¤„ç†

        next_table = title_tag.find_next("table")
        if next_table:
            grade_sections.append((pure_grade_title, next_table))
    # --------------------------------------------------------------------------------

    if not grade_sections:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆå¹´çº§åˆ†åŒº")
        return
    print(f"\nğŸ” å…±æ‰¾åˆ° {len(grade_sections)} ä¸ªæœ‰æ•ˆå¹´çº§åˆ†åŒºï¼ˆå·²å»é‡ï¼‰")

    # æŒ‰å¹´çº§å¤„ç†ï¼ˆæ— é‡å¤ï¼‰
    for grade_title, table in grade_sections:
        print(f"\n===== å¼€å§‹å¤„ç†ï¼š{grade_title} =====")
        grade_save_dir = root_path / grade_title
        grade_save_dir.mkdir(parents=True, exist_ok=True)

        secondary_links = []
        a_tags = table.find_all("a")
        for a_tag in a_tags:
            link = a_tag.get("href")
            if link and link.startswith("http"):
                secondary_links.append(link)

        if not secondary_links:
            print(f"âš ï¸ {grade_title} è¡¨æ ¼æ— æœ‰æ•ˆé“¾æ¥")
            continue
        print(f"ğŸ”— {grade_title} æ‰¾åˆ° {len(secondary_links)} ä¸ªäºŒçº§é¡µé¢é“¾æ¥")

        for idx, link in enumerate(secondary_links, 1):
            print(f"\n--- å¤„ç† {grade_title} ç¬¬ {idx}/{len(secondary_links)} ä¸ªé“¾æ¥ ---")
            extract_secondary_audio(link, grade_save_dir)

    print(f"\nğŸ‰ æ‰€æœ‰å¹´çº§éŸ³é¢‘å¤„ç†å®Œæˆï¼æ€»ç›®å½•ï¼š{root_path}")

if __name__ == "__main__":
    MAIN_ARTICLE_URL = "https://mp.weixin.qq.com/s/1sdIH_nKmo5qT4p61waqwQ"
    ROOT_SAVE_DIR = "./"
    crawl_grade_audio(MAIN_ARTICLE_URL, ROOT_SAVE_DIR)
